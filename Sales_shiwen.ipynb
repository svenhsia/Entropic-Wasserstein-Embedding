{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from time import time\n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s - %(levelname)s - %(message)s', level=logging.INFO)\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import networkx as nx\n",
    "# import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cdist(X, Y):\n",
    "    X2 = tf.reduce_sum(tf.square(X), 1)\n",
    "    Y2 = tf.reduce_sum(tf.square(Y), 1)\n",
    "    X2 = tf.reshape(X2, [-1, 1])\n",
    "    Y2 = tf.reshape(Y2, [1, -1])\n",
    "    # return pairwise euclidead difference matrix\n",
    "    distances = tf.sqrt(tf.maximum(\n",
    "        X2 + Y2 - 2 * tf.matmul(X, Y, False, True), 0.0))\n",
    "    assert distances.shape == [X.shape[0], Y.shape[0]]\n",
    "    return distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_T(K, u, v, n_iter, tol):\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "    -----------\n",
    "        D: 2D array, [M, N]\n",
    "        r: 1D array, [M, ]\n",
    "        c: 1D array, [N, ]\n",
    "        lambd: regularization parameter in Sinkhorn divergence\n",
    "        p: power of the Wasserstein space\n",
    "        n_iter: number of iterations for matrix balancing\n",
    "        tol: tolerance for stopping matrix balancing iterations\n",
    "    \"\"\"\n",
    "    K_tilde = 1. / u * K\n",
    "    r = tf.zeros([int(u.shape[0]), 1], dtype=tf.float64)\n",
    "    r_new = tf.ones([int(u.shape[0]), 1], dtype=tf.float64)\n",
    "\n",
    "    def cond(r, r_new):\n",
    "        r_enter = tf.reduce_any(tf.abs(r_new - r) > tol)\n",
    "        return r_enter\n",
    "\n",
    "    def body(r, r_new):\n",
    "        r = r_new\n",
    "        r_new = 1. / tf.matmul(K_tilde, v / tf.matmul(K, r, True, False))\n",
    "        return [r, r_new]\n",
    "\n",
    "    _, r = tf.while_loop(cond, body, [r, r_new], maximum_iterations=n_iter)\n",
    "    c = v / tf.matmul(K, r, True, False)\n",
    "\n",
    "    T_opt = tf.matmul(tf.diag(tf.reshape(r, (-1,))),\n",
    "                      tf.matmul(K, tf.diag(tf.reshape(c, (-1,)))))\n",
    "\n",
    "    return T_opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wasserstein_distance(n1, n2, embeddings, u, v, lambd, p, n_iter, tol):\n",
    "    support_1 = embeddings[n1, :, :]\n",
    "    support_2 = embeddings[n2, :, :]\n",
    "    D = cdist(support_1, support_2)\n",
    "    D_p = tf.pow(D, p)\n",
    "    K = tf.exp(-D_p / lambd)\n",
    "    T = compute_T(K, u, v, n_iter, tol)\n",
    "\n",
    "    # distance = tf.trace(tf.matmul(D_p, T, False, True)) + lambd * \\\n",
    "    #     tf.trace(tf.matmul(T, tf.log(T) -\n",
    "    #                        tf.ones(T.shape, dtype=tf.float64), False, True))\n",
    "    distance = tf.trace(tf.matmul(D_p, T, False, True))\n",
    "    return distance\n",
    "\n",
    "def wasserstein_distances(pairs, embeddings, u, v, lambd, p, n_iter, tol):\n",
    "    results = tf.map_fn(lambda x: wasserstein_distance(\n",
    "        x[0], x[1], embeddings, u, v, lambd, p, n_iter, tol), pairs, dtype=tf.float64)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_distance(n1, n2, embeddings):\n",
    "    v1 = embeddings[n1, :]\n",
    "    v2 = embeddings[n2, :]\n",
    "    distance = tf.sqrt(tf.reduce_sum(tf.square(v1 - v2)))\n",
    "    return distance\n",
    "\n",
    "def euclidean_distances(pairs, embeddings):\n",
    "    results = tf.map_fn(lambda x: euclidean_distance(x[0], x[1], embeddings), pairs, dtype=tf.float64)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hyperbolic_distance(n1, n2, embeddings, eps):\n",
    "    v1 = embeddings[n1, :]\n",
    "    v2 = embeddings[n2, :]\n",
    "    norm1 = tf.norm(v1)\n",
    "    norm2 = tf.norm(v2)\n",
    "    v1 = tf.cond(tf.greater_equal(norm1, 1), lambda: v1 / norm1 - eps, lambda: v1)\n",
    "    v2 = tf.cond(tf.greater_equal(norm2, 1), lambda: v2 / norm2 - eps, lambda: v2)\n",
    "    \n",
    "    distance = tf.acosh(1 + 2 * tf.reduce_sum(tf.square(v1 - v2)) / ((1 - tf.reduce_sum(tf.square(v1))) * (1 - tf.reduce_sum(tf.square(v2)))))\n",
    "    return distance\n",
    "\n",
    "def hyperbolic_distances(pairs, embeddings, eps):\n",
    "    results = tf.map_fn(lambda x: hyperbolic_distance(x[0], x[1], embeddings, eps), pairs, dtype=tf.float64)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kl_distance(n1, n2, embeddings, eps):\n",
    "    v1 = embeddings[n1, :]\n",
    "    v2 = embeddings[n2, :]\n",
    "    min1 = tf.reduce_min(v1)\n",
    "    min2 = tf.reduce_min(v2)\n",
    "    v1 = tf.cond(tf.less_equal(min1, 0), lambda: v1 - min1 + eps, lambda: v1)\n",
    "    v2 = tf.cond(tf.less_equal(min2, 0), lambda: v2 - min2 + eps, lambda: v2)\n",
    "    v1 = v1 / tf.norm(v1)\n",
    "    v2 = v2 / tf.norm(v2)\n",
    "    kl = (tf.reduce_sum(v1 * (tf.log(v1) - tf.log(v2))) + tf.reduce_sum(v2 * (tf.log(v2) - tf.log(v1)))) / 2\n",
    "    return kl\n",
    "\n",
    "def kl_distances(pairs, embeddings, eps):\n",
    "    results = tf.map_fn(lambda x: kl_distance(x[0], x[1], embeddings, eps), pairs, dtype=tf.float64)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(node_pairs, obj_distances, embedding_type='Euc', n_epochs=500, learning_rate=0.01, u_v=None, nodes=128, embed_dim=20, ground_dim=2, lambd=1.0, p=1, mat_bal_iter=20, mat_bal_tol=1e-5, eps=1e-5):\n",
    "    if u_v is None:\n",
    "        u = tf.ones([embed_dim, 1], dtype=tf.float64) / embed_dim\n",
    "        v = tf.ones([embed_dim, 1], dtype=tf.float64) / embed_dim\n",
    "    \n",
    "    n_nodes = int(obj_distances.shape[0])\n",
    "\n",
    "    Node_Pairs = tf.placeholder(dtype=tf.int32, shape=[n_nodes, 2], name='Node_Pairs')\n",
    "    Obj_Distances = tf.placeholder(dtype=tf.float64, shape=[n_nodes], name='Obj_Distances')\n",
    "    Lambd = tf.placeholder(dtype=tf.float64, shape=(), name='Lambd')\n",
    "    Learning_rate = tf.placeholder(dtype=tf.float64, shape=(), name='Learning_rate')\n",
    "\n",
    "    if embedding_type == 'Wass':\n",
    "        Embeddings = tf.Variable(tf.random.uniform(\n",
    "        [nodes, embed_dim, ground_dim], dtype=tf.float64), name='Embeddings')\n",
    "        Embed_Distances = wasserstein_distances(Node_Pairs, Embeddings, u, v, Lambd, p, mat_bal_iter, mat_bal_tol)\n",
    "    elif embedding_type == 'Hyper':\n",
    "        Embeddings = tf.Variable(0.002 * tf.random.uniform([nodes, embed_dim], dtype=tf.float64) - 0.001, name='Embeddings')\n",
    "        Embed_Distances = hyperbolic_distances(Node_Pairs, Embeddings, eps)\n",
    "    elif embedding_type == 'KL':\n",
    "        Embeddings = tf.Variable(tf.random.uniform([nodes, embed_dim], dtype=tf.float64), name='Embeddings')\n",
    "        Embed_Distances = kl_distances(Node_Pairs, Embeddings, eps)\n",
    "    else:\n",
    "        Embeddings = tf.Variable(tf.random.uniform([nodes, embed_dim], dtype=tf.float64), name='Embeddings')\n",
    "        Embed_Distances = euclidean_distances(Node_Pairs, Embeddings)\n",
    "\n",
    "    Loss = tf.reduce_mean(tf.abs(Embed_Distances - Obj_Distances) / Obj_Distances)\n",
    "    Jac = tf.gradients(ys=Embed_Distances, xs=Embeddings)\n",
    "    optimizer = tf.train.AdamOptimizer(Learning_rate).minimize(Loss)\n",
    "    init_op = tf.global_variables_initializer()\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(init_op)\n",
    "        # Lists for storing the changing Cost and Accuracy in every Epoch\n",
    "        loss_history = []\n",
    "        time_history = []\n",
    "\n",
    "        # best_loss = 1000\n",
    "        # early_stopping_counter = 0\n",
    "        start_time = time()\n",
    "        for epoch in range(n_epochs):\n",
    "           # Running the Optimizer\n",
    "            _, embeddings, embed_distances, loss, jac = sess.run([optimizer, Embeddings, Embed_Distances, Loss, Jac], feed_dict={Node_Pairs: node_pairs, Obj_Distances: obj_distances, Lambd: lambd, Learning_rate: learning_rate})\n",
    "            if np.isnan(loss):\n",
    "                raise RuntimeError(\"Loss is NaN.\")\n",
    "            # Storing loss to the history\n",
    "            loss_history.append(loss)\n",
    "            # Storing consumed time\n",
    "            time_history.append(time() - start_time)\n",
    "            # Displaying result on current Epoch\n",
    "            if epoch % 10 == 0:\n",
    "                logging.info(\"Epoch: {}/{}, loss: {}\".format(epoch+1, n_epochs, loss))\n",
    "            # Early stopping check\n",
    "            if epoch > 20 and np.mean(loss_history[-15:-5]) - loss_history[-1] < 1e-4:\n",
    "                logging.info(\"Early Stopped: 10 consecutive epochs with loss improvement {}\".format(loss_history[-2]-loss_history[-1]))\n",
    "                break\n",
    "            # if loss < best_loss:\n",
    "            #     best_loss = loss\n",
    "            #     early_stopping_counter = 0\n",
    "            # else:\n",
    "            #     early_stopping_counter += 1\n",
    "            # if early_stopping_counter >= patience:\n",
    "            #     break\n",
    "    return embeddings, loss_history, time_history, embed_distances, jac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-04-28 19:25:24,521 - INFO - Load DTW distance data from local file\n",
      "2019-04-28 19:25:25,014 - INFO - node pairs shape: (328455, 2), obj_distances shape: (328455,)\n"
     ]
    }
   ],
   "source": [
    "org_distances = np.loadtxt('./data/Sales_Transaction_Dataset.dist', delimiter=',')\n",
    "logging.info(\"Load DTW distance data from local file\")\n",
    "\n",
    "file_name = 'Sales'\n",
    "eps = 1e-5\n",
    "\n",
    "embed_dims = [30]\n",
    "n_epochs = 500\n",
    "num_nodes = org_distances.shape[0]\n",
    "\n",
    "node_pairs = np.array([[i, j] for i in range(num_nodes) for j in range(i+1, num_nodes)])\n",
    "obj_distances = np.array([org_distances[i, j] for i in range(num_nodes) for j in range(i+1, num_nodes)]) + eps\n",
    "\n",
    "logging.info(\"node pairs shape: {}, obj_distances shape: {}\".format(\n",
    "    node_pairs.shape, obj_distances.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_dim = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import squareform\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, series = load_time_series('./data/Sales_Transactions_Dataset_Weekly.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_dist_matrix = squareform(obj_distances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Normalized 0</th>\n",
       "      <th>Normalized 1</th>\n",
       "      <th>Normalized 2</th>\n",
       "      <th>Normalized 3</th>\n",
       "      <th>Normalized 4</th>\n",
       "      <th>Normalized 5</th>\n",
       "      <th>Normalized 6</th>\n",
       "      <th>Normalized 7</th>\n",
       "      <th>Normalized 8</th>\n",
       "      <th>Normalized 9</th>\n",
       "      <th>...</th>\n",
       "      <th>Normalized 42</th>\n",
       "      <th>Normalized 43</th>\n",
       "      <th>Normalized 44</th>\n",
       "      <th>Normalized 45</th>\n",
       "      <th>Normalized 46</th>\n",
       "      <th>Normalized 47</th>\n",
       "      <th>Normalized 48</th>\n",
       "      <th>Normalized 49</th>\n",
       "      <th>Normalized 50</th>\n",
       "      <th>Normalized 51</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 52 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Normalized 0  Normalized 1  Normalized 2  Normalized 3  Normalized 4  \\\n",
       "229           0.0           0.0           1.0           0.0           0.0   \n",
       "227           0.0           0.0           0.0           0.0           0.0   \n",
       "\n",
       "     Normalized 5  Normalized 6  Normalized 7  Normalized 8  Normalized 9  \\\n",
       "229           0.0           0.0           0.0           0.0           0.0   \n",
       "227           0.0           0.0           0.0           0.0           0.0   \n",
       "\n",
       "     ...  Normalized 42  Normalized 43  Normalized 44  Normalized 45  \\\n",
       "229  ...            0.0            0.0            0.0            0.0   \n",
       "227  ...            0.0            0.0            0.0            0.0   \n",
       "\n",
       "     Normalized 46  Normalized 47  Normalized 48  Normalized 49  \\\n",
       "229            0.0            0.0            0.0            0.0   \n",
       "227            0.0            1.0            0.0            0.0   \n",
       "\n",
       "     Normalized 50  Normalized 51  \n",
       "229            0.0            0.0  \n",
       "227            0.0            0.0  \n",
       "\n",
       "[2 rows x 52 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series.iloc[[229, 227], :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0. inf inf ... inf inf inf]\n",
      " [inf  0.  0. ...  2.  2.  2.]\n",
      " [inf  0.  0. ...  2.  2.  2.]\n",
      " ...\n",
      " [inf  2.  2. ...  0.  0.  0.]\n",
      " [inf  2.  2. ...  0.  0.  0.]\n",
      " [inf  2.  2. ...  0.  0.  0.]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DTWdistance(series.iloc[227, :], series.iloc[229, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-04-28 19:25:28,916 - INFO - Running Euclidean embedding, embed dim=30\n",
      "2019-04-28 19:26:31,421 - INFO - Epoch: 1/500, loss: 321.494426584417\n",
      "2019-04-28 19:36:50,103 - INFO - Epoch: 11/500, loss: 66.39597250352524\n",
      "2019-04-28 19:47:09,431 - INFO - Epoch: 21/500, loss: 25.860731877119388\n",
      "2019-04-28 19:57:40,175 - INFO - Epoch: 31/500, loss: 16.187375122036343\n"
     ]
    }
   ],
   "source": [
    "# Euclidean\n",
    "logging.info(\"Running Euclidean embedding, embed dim={}\".format(embed_dim))\n",
    "embeddings, loss_history, time_history, embed_distances, jac = train(\n",
    "    node_pairs, obj_distances, embedding_type='Euc', embed_dim=embed_dim, \n",
    "    learning_rate=0.1, n_epochs=n_epochs, nodes=num_nodes)\n",
    "# np.savez('./results/{}_{}_{}'.format(file_name, 'Euclidean', embed_dim), \n",
    "#     embeddings=embeddings, loss=loss_history, time=time_history, \n",
    "#     embed_distances=embed_distances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperbolic\n",
    "logging.info(\"Running Hyperbolic embedding, embed dim={}\".format(embed_dim))\n",
    "while True:\n",
    "    try:\n",
    "        embeddings, loss_history, time_history, embed_distances, jac = train(\n",
    "            node_pairs, obj_distances, embedding_type='Hyper', embed_dim=embed_dim, \n",
    "            learning_rate=0.01, n_epochs=n_epochs, nodes=num_nodes)\n",
    "        break\n",
    "    except RuntimeError:\n",
    "        logging.warning(\"Got Loss NaN\")\n",
    "        continue\n",
    "# np.savez('./results/{}_{}_{}'.format(file_name, 'Hyperbolic', embed_dim), \n",
    "#     embeddings=embeddings, loss=loss_history, time=time_history, \n",
    "#     embed_distances=embed_distances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wass R2\n",
    "logging.info(\"Running Wasserstein R2 embedding, embed dim={}\".format(embed_dim))\n",
    "embeddings, loss_history, time_history, embed_distances, jac = train(\n",
    "    node_pairs, obj_distances, embedding_type='Wass', embed_dim=embed_dim, \n",
    "    learning_rate=0.1, n_epochs=n_epochs, ground_dim=2, nodes=num_nodes)\n",
    "# np.savez('./results/{}_{}_{}'.format(file_name, 'WassR2', embed_dim), \n",
    "#     embeddings=embeddings, loss=loss_history, time=time_history, \n",
    "#     embed_distances=embed_distances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KL\n",
    "logging.info(\"Running KL embedding, embed dim={}\".format(embed_dim))\n",
    "embeddings, loss_history, time_history, embed_distances, jac = train(\n",
    "    node_pairs, obj_distances, embedding_type='KL', embed_dim=embed_dim, \n",
    "    learning_rate=0.01, n_epochs=n_epochs, nodes=num_nodes)\n",
    "# np.savez('./results/{}_{}_{}'.format(file_name, 'KL', embed_dim), \n",
    "#     embeddings=embeddings, loss=loss_history, time=time_history, \n",
    "#     embed_distances=embed_distances)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
